{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To predict whether the home team will win Indian Premier League Cricket Match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Chandra Kumar Basavaraju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective : To predict whether the home team will win the Indian Premier League cricket match.\n",
    "\n",
    "Project Description :\n",
    "The goal is to predict if the home team will WIN the Indian Premier League game based on their past of the team and the players.\n",
    "\n",
    "Information required about the game for the prediction :\n",
    "1. Home team \n",
    "2. Visiting team\n",
    "3. Who won the toss?\n",
    "4. What did the toss winner opted to (bat first or field first)?\n",
    "\n",
    "Data Collected :\n",
    "1. Details of all the games played in the league till date from the beginning in 2008. \n",
    "2. IPL Records of all the players representing the current teams in the league.\n",
    "\n",
    "Features extracted and used in the model :\n",
    "1. Did home team win the toss?\n",
    "2. Did home team bat first?\n",
    "3. Home team's batting average\n",
    "4. Home team's bowling average\n",
    "5. Home team's winning rate\n",
    "6. Visiting team's batting average\n",
    "7. Visiting team's bowling average\n",
    "8. Visiting team's winning rate\n",
    "\n",
    "\n",
    "Target :\n",
    "1. Did the home team win the game?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metric : Recall/True Positive Rate/Sensitivity\n",
    "(Of the actual positives how many were predicted positive)\n",
    "\n",
    "Recall seemed appropriate as we are predicting for each game whether the home team will win the game or not?\n",
    "So, recall tells out of all the matches where home team wins, how many did the model predict correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Instances :  572\n",
      "Number of features : 8\n",
      "Input classes :  ['Did home team win the toss?', 'Did Home team bat first?', \"Home Team's Winning Rate\", \"Away Team's Winning Rate\", \"Home Team's Batting Average\", \"Home team's Bowling Average\", \"Away Team's Batting Average\", \"Away team's Bowling Average\"]\n",
      "Output class :  Did home team win the match?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,roc_auc_score,f1_score,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "class IPL:\n",
    "    def load_ipl():\n",
    "        with open('DATA_FINAL5.csv') as csv_file:\n",
    "            data_file = csv.reader(csv_file)\n",
    "            temp = next(data_file)\n",
    "            a = int(temp[0])\n",
    "            b = int(temp[1])\n",
    "            data = np.empty((a,b),dtype=object)\n",
    "            target = np.empty((a,),dtype=object)\n",
    "            feature_names = next(data_file)\n",
    "            print('Number of Instances : ',a)\n",
    "            print('Number of features :',b)\n",
    "            print('Input classes : ',feature_names[:-1])\n",
    "            print('Output class : ',feature_names[-1])\n",
    "                        \n",
    "            for i,ir in enumerate(data_file):\n",
    "                data[i] = np.asarray(ir[:-1],dtype=object)\n",
    "                target[i] = ir[-1]\n",
    "                            \n",
    "            return data, target,feature_names\n",
    "    def predict_random(X):\n",
    "        r = len(X)\n",
    "        Y = np.empty((r,),dtype=int)\n",
    "        for i in range(r):\n",
    "            Y[i] = random.randint(0,1)\n",
    "        return Y\n",
    "    def predict_majority_class(X):\n",
    "        r = len(X)\n",
    "        Y = np.empty((r,),dtype=int)\n",
    "        for i in range(r):\n",
    "            Y[i] = 1 #majority class in target train is 0\n",
    "        return Y\n",
    "\n",
    "X, Y, feature_names = IPL.load_ipl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target class :  Counter({1: 309, 0: 263})\n",
      "\n",
      "Performance when prediction is random : \n",
      "\n",
      "pred_rand_accuracy : 0.512\n",
      "pred_rand_precision : 0.549\n",
      "pred_rand_recall : 0.547\n",
      "pred_rand_roc_auc : 0.509\n",
      "pred_rand_f1 : 0.548\n",
      "\n",
      "Performance when predicting the majority class always : \n",
      "\n",
      "pred_majority_accuracy : 0.540\n",
      "pred_majority_precision : 0.540\n",
      "pred_majority_recall : 1.000\n",
      "pred_majority_roc_auc : 0.500\n",
      "pred_rand_f1 : 0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "#print(le.classes_)\n",
    "target = le.transform(Y)\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(X[:,0])\n",
    "T1 = le1.transform(X[:,0])\n",
    "T1 = np.transpose(T1)\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(X[:,1])\n",
    "T2 = le2.transform(X[:,1])\n",
    "T2 = np.transpose(T2)\n",
    "\n",
    "temp = np.column_stack((T1,T2))\n",
    "\n",
    "temp = np.column_stack((temp,np.transpose(X[:,2])))\n",
    "temp = np.column_stack((temp,np.transpose(X[:,3])))\n",
    "#le3 = preprocessing.LabelEncoder()\n",
    "#le3.fit(X[:,2])\n",
    "#V = le3.transform(X[:,2])\n",
    "#V = np.transpose(V)\n",
    "\n",
    "#temp = np.column_stack((temp,V))\n",
    "\n",
    "#le4 = preprocessing.LabelEncoder()\n",
    "#le4.fit(X[:,2])\n",
    "#HT = le4.transform(X[:,2])\n",
    "#HT = np.transpose(HT)\n",
    "\n",
    "#temp = np.column_stack((temp,HT))\n",
    "\n",
    "#le5 = preprocessing.LabelEncoder()\n",
    "#le5.fit(X[:,3])\n",
    "#ST = le5.transform(X[:,3])\n",
    "#ST = np.transpose(ST)\n",
    "\n",
    "#temp = np.column_stack((temp,ST))\n",
    "\n",
    "#le6 = preprocessing.LabelEncoder()\n",
    "#le6.fit(X[:,4])\n",
    "#TW = le6.transform(X[:,4])\n",
    "#TW = np.transpose(TW)\n",
    "\n",
    "#temp = np.column_stack((temp,TW))\n",
    "\n",
    "#le7 = preprocessing.LabelEncoder()\n",
    "#le7.fit(X[:,5])\n",
    "#TD = le7.transform(X[:,5])\n",
    "#TD = np.transpose(TD)\n",
    "\n",
    "#temp = np.column_stack((temp,TD))\n",
    "\n",
    "i = 4\n",
    "nof = len(X[0])\n",
    "for k in range(i,nof):\n",
    "    kthFeature = X[:,k]\n",
    "    kthFeature_scaled = preprocessing.scale(kthFeature)\n",
    "    a = np.transpose(kthFeature_scaled)\n",
    "    temp = np.column_stack((temp,a))\n",
    "\n",
    "input_preprocessed = temp\n",
    "\n",
    "\n",
    "distribution_of_target_class = Counter(target)\n",
    "print('Distribution of target class : ',distribution_of_target_class)\n",
    "\n",
    "#predicting randomly\n",
    "Y_pred_rand = IPL.predict_random(input_preprocessed)\n",
    "\n",
    "print('\\nPerformance when prediction is random : \\n')\n",
    "\n",
    "pred_rand_accuracy = accuracy_score(target, Y_pred_rand)\n",
    "print('pred_rand_accuracy : %0.3f'%pred_rand_accuracy)\n",
    "\n",
    "pred_rand_precision = precision_score(target, Y_pred_rand)\n",
    "print('pred_rand_precision : %0.3f'%pred_rand_precision)\n",
    "\n",
    "pred_rand_recall = recall_score(target, Y_pred_rand)\n",
    "print('pred_rand_recall : %0.3f'%pred_rand_recall)\n",
    "\n",
    "pred_rand_roc_auc = roc_auc_score(target,Y_pred_rand)\n",
    "print('pred_rand_roc_auc : %0.3f'%pred_rand_roc_auc)\n",
    "\n",
    "pred_rand_f1 = f1_score(target,Y_pred_rand)\n",
    "print('pred_rand_f1 : %0.3f'%pred_rand_f1)\n",
    "\n",
    "\n",
    "\n",
    "#predicting the majority class always i.e, 0 (Team 1 wins always)\n",
    "Y_pred_majority = IPL.predict_majority_class(input_preprocessed)\n",
    "\n",
    "print('\\nPerformance when predicting the majority class always : \\n')\n",
    "\n",
    "pred_majority_accuracy = accuracy_score(target,Y_pred_majority)\n",
    "print('pred_majority_accuracy : %0.3f'%pred_majority_accuracy)\n",
    "\n",
    "pred_majority_precision = precision_score(target,Y_pred_majority)\n",
    "print('pred_majority_precision : %0.3f'%pred_majority_precision)\n",
    "\n",
    "pred_majority_recall = recall_score(target,Y_pred_majority)\n",
    "print('pred_majority_recall : %0.3f'%pred_majority_recall)\n",
    "\n",
    "pred_majority_roc_auc = roc_auc_score(target,Y_pred_majority)\n",
    "print('pred_majority_roc_auc : %0.3f'%pred_majority_roc_auc)\n",
    "\n",
    "pred_majority_f1 = f1_score(target,Y_pred_majority)\n",
    "print('pred_rand_f1 : %0.3f'%pred_majority_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance of decision tree classifier : \n",
      "\n",
      "\n",
      "Criterion for Decision Tree is :  entropy\n",
      "Accuracy of DT with CV : 0.561\n",
      "Precision of DT with CV : 0.600\n",
      "Recall of DT with CV : 0.531\n",
      "F1 of DT with CV : 0.560\n",
      "AUC of DT with CV : 0.554\n",
      "\n",
      "Criterion for Decision Tree is :  gini\n",
      "Accuracy of DT with CV : 0.551\n",
      "Precision of DT with CV : 0.601\n",
      "Recall of DT with CV : 0.534\n",
      "F1 of DT with CV : 0.555\n",
      "AUC of DT with CV : 0.551\n",
      "\n",
      "Performance of Guassian Naive Bayes classifier : \n",
      "\n",
      "Accuracy of GNB with CV : 0.593\n",
      "Precision of GNB with CV : 0.603\n",
      "Recall of GNB with CV : 0.735\n",
      "F1 of GNB with CV : 0.661\n",
      "AUC of GNB with CV : 0.596\n"
     ]
    }
   ],
   "source": [
    "A = 'accuracy'\n",
    "P = 'precision'\n",
    "R = 'recall'\n",
    "F1 = 'f1'\n",
    "ROC = 'roc_auc'\n",
    "criterions = ['entropy','gini']\n",
    "\n",
    "#decision tree classifier\n",
    "print(\"\\nPerformance of decision tree classifier : \\n\")\n",
    "for cr in criterions: \n",
    "    print(\"\\nCriterion for Decision Tree is : \",cr)\n",
    "    dt = DecisionTreeClassifier(random_state=None,criterion=cr)\n",
    "    dt_acc = cross_val_score(dt, input_preprocessed, target, cv=10,scoring=A)\n",
    "    print('Accuracy of DT with CV : %0.3f'%np.mean(dt_acc))\n",
    "\n",
    "    dt_pre = cross_val_score(dt, input_preprocessed, target, cv=10,scoring=P)\n",
    "    print('Precision of DT with CV : %0.3f'%np.mean(dt_pre))\n",
    "\n",
    "    dt_rec = cross_val_score(dt, input_preprocessed, target, cv=10,scoring=R)\n",
    "    print('Recall of DT with CV : %0.3f'%np.mean(dt_rec))\n",
    "\n",
    "    dt_f1 = cross_val_score(dt, input_preprocessed, target, cv=10,scoring=F1)\n",
    "    print('F1 of DT with CV : %0.3f'%np.mean(dt_f1))\n",
    "\n",
    "    dt_auc = cross_val_score(dt, input_preprocessed, target, cv=10,scoring=ROC)\n",
    "    print(\"AUC of DT with CV : %0.3f\"%np.mean(dt_auc))\n",
    "\n",
    "#guassian naive bayes classifier\n",
    "print(\"\\nPerformance of Guassian Naive Bayes classifier : \\n\")\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb_acc = cross_val_score(gnb,input_preprocessed,target,scoring=A,cv=10)\n",
    "print('Accuracy of GNB with CV : %0.3f'%np.mean(gnb_acc))\n",
    "\n",
    "gnb_pre = cross_val_score(gnb,input_preprocessed,target,scoring=P,cv=10)\n",
    "print('Precision of GNB with CV : %0.3f'%np.mean(gnb_pre))\n",
    "\n",
    "gnb_rec = cross_val_score(gnb,input_preprocessed,target,scoring=R,cv=10)\n",
    "print('Recall of GNB with CV : %0.3f'%np.mean(gnb_rec))\n",
    "\n",
    "gnb_f1 = cross_val_score(gnb,input_preprocessed,target,scoring=F1,cv=10)\n",
    "print('F1 of GNB with CV : %0.3f'%np.mean(gnb_f1))\n",
    "\n",
    "gnb_auc = cross_val_score(gnb, input_preprocessed, target,scoring=ROC,cv=10)\n",
    "print(\"AUC of GNB with CV : %0.3f\"%np.mean(gnb_auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance of Logistic Regression model :\n",
      "\n",
      "\n",
      "Penalty =  l1\n",
      "\n",
      "c =  0.001\n",
      "Accuracy of LR with CV : 0.460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of LR with CV : 0.000\n",
      "Recall of LR with CV : 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of LR with CV : 0.000\n",
      "AUC of LR with CV : 0.500\n",
      "\n",
      "c =  0.01\n",
      "Accuracy of LR with CV : 0.460\n",
      "Precision of LR with CV : 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of LR with CV : 0.000\n",
      "F1 of LR with CV : 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of LR with CV : 0.500\n",
      "\n",
      "c =  0.1\n",
      "Accuracy of LR with CV : 0.526\n",
      "Precision of LR with CV : 0.536\n",
      "Recall of LR with CV : 0.909\n",
      "F1 of LR with CV : 0.674\n",
      "AUC of LR with CV : 0.512\n",
      "\n",
      "c =  1\n",
      "Accuracy of LR with CV : 0.605\n",
      "Precision of LR with CV : 0.609\n",
      "Recall of LR with CV : 0.754\n",
      "F1 of LR with CV : 0.674\n",
      "AUC of LR with CV : 0.614\n",
      "\n",
      "c =  10\n",
      "Accuracy of LR with CV : 0.603\n",
      "Precision of LR with CV : 0.612\n",
      "Recall of LR with CV : 0.728\n",
      "F1 of LR with CV : 0.664\n",
      "AUC of LR with CV : 0.627\n",
      "\n",
      "c =  100\n",
      "Accuracy of LR with CV : 0.603\n",
      "Precision of LR with CV : 0.612\n",
      "Recall of LR with CV : 0.725\n",
      "F1 of LR with CV : 0.663\n",
      "AUC of LR with CV : 0.627\n",
      "\n",
      "Penalty =  l2\n",
      "\n",
      "c =  0.001\n",
      "Accuracy of LR with CV : 0.531\n",
      "Precision of LR with CV : 0.538\n",
      "Recall of LR with CV : 0.932\n",
      "F1 of LR with CV : 0.682\n",
      "AUC of LR with CV : 0.525\n",
      "\n",
      "c =  0.01\n",
      "Accuracy of LR with CV : 0.538\n",
      "Precision of LR with CV : 0.545\n",
      "Recall of LR with CV : 0.877\n",
      "F1 of LR with CV : 0.672\n",
      "AUC of LR with CV : 0.533\n",
      "\n",
      "c =  0.1\n",
      "Accuracy of LR with CV : 0.560\n",
      "Precision of LR with CV : 0.568\n",
      "Recall of LR with CV : 0.770\n",
      "F1 of LR with CV : 0.653\n",
      "AUC of LR with CV : 0.555\n",
      "\n",
      "c =  1\n",
      "Accuracy of LR with CV : 0.598\n",
      "Precision of LR with CV : 0.603\n",
      "Recall of LR with CV : 0.754\n",
      "F1 of LR with CV : 0.669\n",
      "AUC of LR with CV : 0.600\n",
      "\n",
      "c =  10\n",
      "Accuracy of LR with CV : 0.603\n",
      "Precision of LR with CV : 0.611\n",
      "Recall of LR with CV : 0.735\n",
      "F1 of LR with CV : 0.667\n",
      "AUC of LR with CV : 0.625\n",
      "\n",
      "c =  100\n",
      "Accuracy of LR with CV : 0.603\n",
      "Precision of LR with CV : 0.612\n",
      "Recall of LR with CV : 0.725\n",
      "F1 of LR with CV : 0.663\n",
      "AUC of LR with CV : 0.628\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression linear model\n",
    "print(\"\\nPerformance of Logistic Regression model :\\n\")\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "penalties = ['l1','l2']\n",
    "for p in penalties:\n",
    "    print(\"\\nPenalty = \",p)\n",
    "    for c in Cs:\n",
    "        print('\\nc = ',c)\n",
    "        lr = LogisticRegression(random_state=0,penalty=p,C=c)\n",
    "        lr_acc = cross_val_score(lr, input_preprocessed, target, cv=10,scoring=A)\n",
    "        print('Accuracy of LR with CV : %0.3f'%np.mean(lr_acc))\n",
    "\n",
    "        lr_pre = cross_val_score(lr, input_preprocessed, target, cv=10,scoring=P)\n",
    "        print('Precision of LR with CV : %0.3f'%np.mean(lr_pre))\n",
    "\n",
    "        lr_recall = cross_val_score(lr, input_preprocessed, target, cv=10,scoring=R)\n",
    "        print('Recall of LR with CV : %0.3f'%np.mean(lr_recall))\n",
    "\n",
    "        lr_f1 = cross_val_score(lr, input_preprocessed, target, cv=10,scoring=F1)\n",
    "        print('F1 of LR with CV : %0.3f'%np.mean(lr_f1))\n",
    "\n",
    "        lr_auc = cross_val_score(lr, input_preprocessed, target, cv=10,scoring=ROC)\n",
    "        print(\"AUC of LR with CV : %0.3f\"%np.mean(lr_auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Model : Logistic Regression with parameter penalty = l2 and C=0.001\n",
      "Recall of LR with CV : 0.932\n",
      "\n",
      "Target Class :  ['Did home team win the match?']\n",
      "\n",
      "Top positive features and their weights : \n",
      "\n",
      "Home Team's Winning Rate \t 0.0129331147595\n",
      "Did home team win the toss? \t 0.0109756188513\n",
      "Away Team's Winning Rate \t 0.00722168796417\n",
      "\n",
      "Top negative features and their weights : \n",
      "\n",
      "Home team's Bowling Average \t -0.0158391398166\n",
      "Away Team's Batting Average \t -0.00724794223902\n",
      "Did Home team bat first? \t -0.00510842086515\n"
     ]
    }
   ],
   "source": [
    "print(\"Chosen Model : Logistic Regression with parameter penalty = l2 and C=0.001\")\n",
    "lr1 = LogisticRegression(random_state=0,penalty='l2',C=0.001)\n",
    "\n",
    "lr1_recall = cross_val_score(lr1, input_preprocessed, target, cv=10,scoring=R)\n",
    "print('Recall of LR with CV : %0.3f'%np.mean(lr1_recall))\n",
    "\n",
    "\n",
    "lr1.fit(input_preprocessed,target)\n",
    "\n",
    "print('\\nTarget Class : ',feature_names[::-1][:1])\n",
    "\n",
    "weights = lr1.coef_[0]\n",
    "sorted_indices = np.argsort(weights)\n",
    "\n",
    "print('\\nTop positive features and their weights : \\n')\n",
    "for i in sorted_indices[::-1][:3]:\n",
    "    print(feature_names[i],'\\t',weights[i])\n",
    "\n",
    "print('\\nTop negative features and their weights : \\n')\n",
    "for i in sorted_indices[:3]:\n",
    "    print(feature_names[i],'\\t',weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
